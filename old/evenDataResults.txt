results after evening out datasets to have equal number of lines per character:

 bang ########################################

	Logistic Regression:
               precision    recall  f1-score   support

           0       0.10      0.18      0.13       687
           1       0.00      0.00      0.00       577
           2       0.19      0.14      0.16      1198
           3       0.24      0.14      0.18      1956
           4       0.23      0.40      0.30      1488
           5       0.16      0.11      0.13       922
           6       0.38      0.43      0.41      2337

    accuracy                           0.25      9165
   macro avg       0.19      0.20      0.19      9165
weighted avg       0.24      0.25      0.23      9165

	Random Forest:
               precision    recall  f1-score   support

           0       0.09      0.19      0.12       687
           1       0.00      0.00      0.00       577
           2       0.16      0.20      0.18      1198
           3       0.27      0.19      0.22      1956
           4       0.23      0.25      0.24      1488
           5       0.12      0.20      0.15       922
           6       0.41      0.31      0.35      2337

    accuracy                           0.22      9165
   macro avg       0.18      0.19      0.18      9165
weighted avg       0.24      0.22      0.22      9165

	Gaussian Naive Bayes:
               precision    recall  f1-score   support

           0       0.08      0.45      0.14       687
           1       0.00      0.00      0.00       577
           2       0.19      0.08      0.11      1198
           3       0.19      0.01      0.02      1956
           4       0.22      0.37      0.28      1488
           5       0.13      0.15      0.14       922
           6       0.40      0.22      0.29      2337

    accuracy                           0.18      9165
   macro avg       0.17      0.18      0.14      9165
weighted avg       0.22      0.18      0.16      9165

	Neural Net:
               precision    recall  f1-score   support

           0       0.11      0.10      0.11       687
           1       0.00      0.00      0.00       577
           2       0.18      0.21      0.20      1198
           3       0.25      0.15      0.19      1956
           4       0.23      0.36      0.28      1488
           5       0.16      0.08      0.11       922
           6       0.36      0.49      0.42      2337

    accuracy                           0.26      9165
   macro avg       0.19      0.20      0.19      9165
weighted avg       0.23      0.26      0.24      9165



 simpsons ########################################

	Logistic Regression:
               precision    recall  f1-score   support

           0       0.27      0.35      0.31      2653
           1       0.53      0.31      0.39      5698
           2       0.20      0.26      0.22      2102
           3       0.27      0.41      0.32      2731
           4       0.00      0.00      0.00       407

    accuracy                           0.32     13591
   macro avg       0.25      0.26      0.25     13591
weighted avg       0.36      0.32      0.32     13591

	Random Forest:
               precision    recall  f1-score   support

           0       0.25      0.29      0.27      2653
           1       0.48      0.33      0.39      5698
           2       0.18      0.27      0.22      2102
           3       0.26      0.32      0.29      2731
           4       0.00      0.00      0.00       407

    accuracy                           0.30     13591
   macro avg       0.23      0.24      0.23     13591
weighted avg       0.33      0.30      0.31     13591

	Gaussian Naive Bayes:
               precision    recall  f1-score   support

           0       0.38      0.13      0.19      2653
           1       0.52      0.21      0.30      5698
           2       0.17      0.40      0.24      2102
           3       0.24      0.49      0.32      2731
           4       0.00      0.00      0.00       407

    accuracy                           0.27     13591
   macro avg       0.26      0.24      0.21     13591
weighted avg       0.37      0.27      0.26     13591

	Neural Net:
               precision    recall  f1-score   support

           0       0.28      0.31      0.29      2653
           1       0.50      0.37      0.43      5698
           2       0.19      0.41      0.26      2102
           3       0.28      0.19      0.22      2731
           4       0.00      0.00      0.00       407

    accuracy                           0.32     13591
   macro avg       0.25      0.26      0.24     13591
weighted avg       0.35      0.32      0.32     13591



 desperate ########################################

	Logistic Regression:
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       808
           1       0.30      0.41      0.34       937
           2       0.29      0.41      0.34       928
           3       0.34      0.37      0.35      1015

    accuracy                           0.31      3688
   macro avg       0.23      0.30      0.26      3688
weighted avg       0.24      0.31      0.27      3688

	Random Forest:
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       808
           1       0.30      0.40      0.34       937
           2       0.28      0.37      0.32       928
           3       0.32      0.39      0.35      1015

    accuracy                           0.30      3688
   macro avg       0.23      0.29      0.25      3688
weighted avg       0.24      0.30      0.26      3688

	Gaussian Naive Bayes:
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       808
           1       0.36      0.19      0.25       937
           2       0.28      0.46      0.35       928
           3       0.31      0.49      0.38      1015

    accuracy                           0.30      3688
   macro avg       0.23      0.29      0.24      3688
weighted avg       0.24      0.30      0.25      3688

	Neural Net:
               precision    recall  f1-score   support

           0       0.00      0.00      0.00       808
           1       0.27      0.62      0.38       937
           2       0.32      0.30      0.31       928
           3       0.37      0.26      0.30      1015

    accuracy                           0.30      3688
   macro avg       0.24      0.29      0.25      3688
weighted avg       0.25      0.30      0.26      3688